{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434f31e0",
   "metadata": {},
   "source": [
    "## 감성 사전을 만들기 위한 형용사 어간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a88a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5543aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어간 추출\n",
    "def extract_stem(words):\n",
    "    okt = Okt()\n",
    "    # 어간 추출\n",
    "    stems = okt.morphs(words,stem=True)\n",
    "    return stems[0] if stems else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37a0c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>review2</th>\n",
       "      <th>adj</th>\n",
       "      <th>verb</th>\n",
       "      <th>noun</th>\n",
       "      <th>exclamation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>희양산</td>\n",
       "      <td>[2일차: 희양산 - 대야산4山_희양산 50m© NAVER Corp.더보기 /Ope...</td>\n",
       "      <td>일차 희양산 대야산희양산 더보기 지도 데이터 지도 컨트롤러 범례부동산거리읍면동시군구...</td>\n",
       "      <td>간단한 시원한 괜찮다 어렵고 길도 험하고 불친절한 그렇지 나쁘지 많은 미끄럽 없는 ...</td>\n",
       "      <td>둘러 삼아 바라본 하면 나오는 찾아 찾아보니 앞서던 넘치고 않았던 않다 거칠어진 기...</td>\n",
       "      <td>일차 희양산 대야산 희양산 더 보기 지도 데이터 지도 컨트롤러 범례 부동산 거리 읍...</td>\n",
       "      <td>휴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>희양산</td>\n",
       "      <td>[몇년전 부봉인가 도명산을 올랐을때 유난히 대머리가 심한 희양산이 눈에 띄어 언젠가...</td>\n",
       "      <td>몇년전 부봉인가 도명산을 올랐을때 유난히 대머리가 심한 희양산이 눈에 띄어 언젠가 ...</td>\n",
       "      <td>심한 뿌옇다 맑아진다니 간략히 희 많지 짧게 덥고 모호한데 예쁘다고 그래 있는 있 ...</td>\n",
       "      <td>올랐을 띄어 가보고 싶었는데 나면 트여 볼거란 들었다 헌데 가르는 기대는 버리지 세...</td>\n",
       "      <td>년전 부 봉인 도명 산 때 대머리 희양산 눈 한번 오늘이 그날 토요일 새벽 비 그 ...</td>\n",
       "      <td>끄응 아 엉</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   희양산  [2일차: 희양산 - 대야산4山_희양산 50m© NAVER Corp.더보기 /Ope...   \n",
       "1   희양산  [몇년전 부봉인가 도명산을 올랐을때 유난히 대머리가 심한 희양산이 눈에 띄어 언젠가...   \n",
       "\n",
       "                                             review2  \\\n",
       "0  일차 희양산 대야산희양산 더보기 지도 데이터 지도 컨트롤러 범례부동산거리읍면동시군구...   \n",
       "1  몇년전 부봉인가 도명산을 올랐을때 유난히 대머리가 심한 희양산이 눈에 띄어 언젠가 ...   \n",
       "\n",
       "                                                 adj  \\\n",
       "0  간단한 시원한 괜찮다 어렵고 길도 험하고 불친절한 그렇지 나쁘지 많은 미끄럽 없는 ...   \n",
       "1  심한 뿌옇다 맑아진다니 간략히 희 많지 짧게 덥고 모호한데 예쁘다고 그래 있는 있 ...   \n",
       "\n",
       "                                                verb  \\\n",
       "0  둘러 삼아 바라본 하면 나오는 찾아 찾아보니 앞서던 넘치고 않았던 않다 거칠어진 기...   \n",
       "1  올랐을 띄어 가보고 싶었는데 나면 트여 볼거란 들었다 헌데 가르는 기대는 버리지 세...   \n",
       "\n",
       "                                                noun exclamation  \n",
       "0  일차 희양산 대야산 희양산 더 보기 지도 데이터 지도 컨트롤러 범례 부동산 거리 읍...           휴  \n",
       "1  년전 부 봉인 도명 산 때 대머리 희양산 눈 한번 오늘이 그날 토요일 새벽 비 그 ...      끄응 아 엉  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1t = pd.read_csv('./data/review_data_1t_2.csv', encoding='utf-8')\n",
    "df_1t.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61e082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>review2</th>\n",
       "      <th>adj</th>\n",
       "      <th>verb</th>\n",
       "      <th>noun</th>\n",
       "      <th>exclamation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>문화</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>친절해요</td>\n",
       "      <td>문화</td>\n",
       "      <td>친절해요</td>\n",
       "      <td>친절해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review label review2   adj verb noun exclamation\n",
       "0      ?    문화     NaN   NaN  NaN  NaN         NaN\n",
       "1   친절해요    문화    친절해요  친절해요  NaN  NaN         NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2t = pd.read_csv('./data/review_data_2t_2.csv', encoding='utf-8')\n",
    "df_2t.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d35b99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>리뷰</th>\n",
       "      <th>음식유형</th>\n",
       "      <th>review2</th>\n",
       "      <th>adj</th>\n",
       "      <th>verb</th>\n",
       "      <th>noun</th>\n",
       "      <th>exclamation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>👍</td>\n",
       "      <td>디저트</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>굿</td>\n",
       "      <td>디저트</td>\n",
       "      <td>굿</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>굿</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  리뷰 음식유형 review2  adj verb noun exclamation\n",
       "0  👍  디저트     NaN  NaN  NaN  NaN         NaN\n",
       "1  굿  디저트       굿  NaN  NaN    굿         NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3t = pd.read_csv('./data/review_data_3t_2.csv', encoding='utf-8')\n",
    "df_3t.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f497ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123983 entries, 0 to 123982\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   label        123983 non-null  object\n",
      " 1   review       123983 non-null  object\n",
      " 2   review2      123983 non-null  object\n",
      " 3   adj          121758 non-null  object\n",
      " 4   verb         122764 non-null  object\n",
      " 5   noun         123833 non-null  object\n",
      " 6   exclamation  30626 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c15362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141254 entries, 0 to 141253\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   review       141254 non-null  object\n",
      " 1   label        141254 non-null  object\n",
      " 2   review2      136766 non-null  object\n",
      " 3   adj          101343 non-null  object\n",
      " 4   verb         59979 non-null   object\n",
      " 5   noun         93857 non-null   object\n",
      " 6   exclamation  1212 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4190b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123749 entries, 0 to 123748\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   리뷰           117078 non-null  object\n",
      " 1   음식유형         123749 non-null  object\n",
      " 2   review2      115595 non-null  object\n",
      " 3   adj          95611 non-null   object\n",
      " 4   verb         64770 non-null   object\n",
      " 5   noun         97115 non-null   object\n",
      " 6   exclamation  1270 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_3t.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c4841",
   "metadata": {},
   "source": [
    "### 형용사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11546e5a",
   "metadata": {},
   "source": [
    "#### 형용사 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dc0763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235178"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복제거전\n",
    "len(' '.join(df_2t['adj'].dropna().sort_values()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4016104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114700\n"
     ]
    }
   ],
   "source": [
    "# 중복제거\n",
    "# 'adj'열 결측치 제거 후 오름차순 정렬후 중복제거 후 공백을 구분자로 한개의 문자열로 만든뒤 공백을 구분자로 리스트 변환\n",
    "adj_list_1t = ' '.join(df_1t['adj'].dropna().sort_values().drop_duplicates()).split()\n",
    "# 리스트 내의 중복 제거\n",
    "adj_list_1t = list(set(adj_list_1t))\n",
    "print(len(adj_list_1t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "357d1ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12912\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "adj_list_2t = ' '.join(df_2t['adj'].dropna().sort_values().drop_duplicates()).split()\n",
    "adj_list_2t = list(set(adj_list_2t))\n",
    "print(len(adj_list_2t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "713ff598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11990\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "adj_list_3t = ' '.join(df_3t['adj'].dropna().sort_values().drop_duplicates()).split()\n",
    "adj_list_3t = list(set(adj_list_3t))\n",
    "print(len(adj_list_3t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdc8c0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19408"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2,3팀 병합 후 중복제거 후 형용사 카운트\n",
    "tmp=pd.concat([pd.Series(adj_list_2t),pd.Series(adj_list_3t)]).drop_duplicates()\n",
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "486aa95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120042"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,2,3팀 병합 후 중복제거 후 형용사 카운트\n",
    "tmp=pd.concat([pd.Series(adj_list_1t),pd.Series(adj_list_2t),pd.Series(adj_list_3t)]).drop_duplicates()\n",
    "len(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa01d95",
   "metadata": {},
   "source": [
    "#### 형용사 어간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9b80b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 114700/114700 [02:06<00:00, 908.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "adj_stem_list_1t = pd.Series(adj_list_1t).progress_map(extract_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0a78a981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        가깝다\n",
       "1       가난하다\n",
       "2       가냘프다\n",
       "3       가녀리다\n",
       "4        가늘다\n",
       "        ... \n",
       "2065     힘나다\n",
       "2066     힘드다\n",
       "2067     힘들다\n",
       "2068     힘없다\n",
       "2069     힘차다\n",
       "Length: 2070, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복제거\n",
    "adj_stem_list_1t_unique = adj_stem_list_1t.drop_duplicates()\n",
    "filtered_adj_stem_list_1t_unique = adj_stem_list_1t_unique[adj_stem_list_1t_unique.map(lambda x:len(x) > 1)]\n",
    "filtered_adj_stem_list_1t = filtered_adj_stem_list_1t_unique.sort_values().reset_index(drop=True)\n",
    "filtered_adj_stem_list_1t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a8a768dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12912/12912 [00:11<00:00, 1137.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "adj_stem_list_2t = pd.Series(adj_list_2t).progress_map(extract_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c4cf8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복제거\n",
    "adj_stem_list_2t_unique = adj_stem_list_2t.drop_duplicates()\n",
    "filtered_adj_stem_list_2t_unique = adj_stem_list_2t_unique[adj_stem_list_2t_unique.map(lambda x:len(x) > 1)]\n",
    "filtered_adj_stem_list_2t = filtered_adj_stem_list_2t_unique.sort_values().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "49410708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       가깝다\n",
       "1      가난하다\n",
       "2       가늘다\n",
       "3      가능하다\n",
       "4      가득하다\n",
       "       ... \n",
       "988     힘나다\n",
       "989     힘드다\n",
       "990     힘들다\n",
       "991     힘없다\n",
       "992     힘차다\n",
       "Length: 993, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_adj_stem_list_2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "85abcdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11990/11990 [00:11<00:00, 1046.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "adj_stem_list_3t = pd.Series(adj_list_3t).progress_map(extract_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b8188c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       가깝다\n",
       "1       가늘다\n",
       "2      가능하다\n",
       "3      가득하다\n",
       "4       가볍다\n",
       "       ... \n",
       "867    희한하다\n",
       "868     힘겹다\n",
       "869     힘드다\n",
       "870     힘들다\n",
       "871     힘차다\n",
       "Length: 872, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복제거\n",
    "adj_stem_list_3t_unique = adj_stem_list_3t.drop_duplicates()\n",
    "filtered_adj_stem_list_3t_unique = adj_stem_list_3t_unique[adj_stem_list_3t_unique.map(lambda x:len(x) > 1)]\n",
    "filtered_adj_stem_list_3t = filtered_adj_stem_list_3t_unique.sort_values().reset_index(drop=True)\n",
    "filtered_adj_stem_list_3t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c66cba",
   "metadata": {},
   "source": [
    "#### 형용사 어간 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "97e97dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(filtered_adj_stem_list_1t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_1t_adj.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c508fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(filtered_adj_stem_list_2t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_2t_adj.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3afe1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(filtered_adj_stem_list_2t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_2t_adj.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "eb48e170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가깝다</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가난하다</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가냘프다</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가녀리다</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가늘다</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     단어  점수\n",
       "0   가깝다 NaN\n",
       "1  가난하다 NaN\n",
       "2  가냘프다 NaN\n",
       "3  가녀리다 NaN\n",
       "4   가늘다 NaN"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv('./data/sentimental_1t_adj.csv', encoding='cp949')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b7702",
   "metadata": {},
   "source": [
    "### 동사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d2e5d",
   "metadata": {},
   "source": [
    "#### 동사 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3d979a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297039\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "verb_list_1t = ' '.join(df_1t['verb'].dropna().sort_values().drop_duplicates()).split()\n",
    "verb_list_1t = list(set(verb_list_1t))\n",
    "print(len(verb_list_1t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7a383132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12912\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "verb_list_2t = ' '.join(df_2t['verb'].dropna().sort_values().drop_duplicates()).split()\n",
    "verb_list_2t = list(set(verb_list_2t))\n",
    "print(len(adj_list_2t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "778c7d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22176\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "verb_list_3t = ' '.join(df_3t['verb'].dropna().sort_values().drop_duplicates()).split()\n",
    "verb_list_3t = list(set(verb_list_3t))\n",
    "print(len(verb_list_3t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0b57c",
   "metadata": {},
   "source": [
    "#### 동사 어간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0339bce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 297039/297039 [05:30<00:00, 900.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "verb_stem_list_1t = pd.Series(verb_list_1t).progress_map(extract_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e32f2697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          가가\n",
       "1          가게\n",
       "2          가계\n",
       "3          가구\n",
       "4          가기\n",
       "        ...  \n",
       "2822    힐끗거리다\n",
       "2823      힘내다\n",
       "2824     힘빠지다\n",
       "2825      힘쓰다\n",
       "2826      힘주다\n",
       "Length: 2827, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복제거\n",
    "verb_stem_list_1t_unique = verb_stem_list_1t.drop_duplicates()\n",
    "filtered_verb_stem_list_1t_unique = verb_stem_list_1t_unique[verb_stem_list_1t_unique.map(lambda x:len(x) > 1)]\n",
    "filtered_verb_stem_list_1t = filtered_verb_stem_list_1t_unique.sort_values().reset_index(drop=True)\n",
    "filtered_verb_stem_list_1t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bcd190f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 27223/27223 [00:25<00:00, 1075.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "verb_stem_list_2t = pd.Series(verb_list_2t).progress_map(extract_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "194b0ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          가게\n",
       "1          가기\n",
       "2       가까워지다\n",
       "3         가꾸다\n",
       "4       가꾸어지다\n",
       "        ...  \n",
       "1275     흥이나다\n",
       "1276     흩날리다\n",
       "1277       흩다\n",
       "1278      힘내다\n",
       "1279      힘쓰다\n",
       "Length: 1280, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복제거\n",
    "verb_stem_list_2t_unique = verb_stem_list_2t.drop_duplicates()\n",
    "filtered_verb_stem_list_2t_unique = verb_stem_list_2t_unique[verb_stem_list_2t_unique.map(lambda x:len(x) > 1)]\n",
    "filtered_verb_stem_list_2t = filtered_verb_stem_list_2t_unique.sort_values().reset_index(drop=True)\n",
    "filtered_verb_stem_list_2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "100cd5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 22176/22176 [00:20<00:00, 1073.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "verb_stem_list_3t = pd.Series(verb_list_3t).progress_map(extract_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "17ce94cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          가게\n",
       "1       가까워지다\n",
       "2         가꾸다\n",
       "3       가꾸어지다\n",
       "4         가누다\n",
       "        ...  \n",
       "1167       흩다\n",
       "1168     흩어지다\n",
       "1169      힘내다\n",
       "1170      힘쓰다\n",
       "1171      힘주다\n",
       "Length: 1172, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복제거\n",
    "verb_stem_list_3t_unique = verb_stem_list_3t.drop_duplicates()\n",
    "filtered_verb_stem_list_3t_unique = verb_stem_list_3t_unique[verb_stem_list_3t_unique.map(lambda x:len(x) > 1)]\n",
    "filtered_verb_stem_list_3t = filtered_verb_stem_list_3t_unique.sort_values().reset_index(drop=True)\n",
    "filtered_verb_stem_list_3t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936f700",
   "metadata": {},
   "source": [
    "#### 동사 어간 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5adeb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(filtered_verb_stem_list_1t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_1t_verb.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "af9ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(filtered_verb_stem_list_1t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_2t_verb.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5d8ce84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(filtered_verb_stem_list_1t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_3t_verb.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c4b3cef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가가</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가게</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가계</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가구</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가기</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   단어  점수\n",
       "0  가가 NaN\n",
       "1  가게 NaN\n",
       "2  가계 NaN\n",
       "3  가구 NaN\n",
       "4  가기 NaN"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv('./data/sentimental_1t_verb.csv', encoding='cp949')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c78583",
   "metadata": {},
   "source": [
    "### 감탄사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70896e",
   "metadata": {},
   "source": [
    "#### 감탄사 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5b0598f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "exclamation_list_1t = ' '.join(df_1t['exclamation'].dropna().sort_values().drop_duplicates()).split()\n",
    "exclamation_list_1t = list(set(exclamation_list_1t))\n",
    "print(len(exclamation_list_1t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2b4c3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "exclamation_list_2t = ' '.join(df_2t['exclamation'].dropna().sort_values().drop_duplicates()).split()\n",
    "exclamation_list_2t = list(set(exclamation_list_2t))\n",
    "print(len(exclamation_list_2t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a526af26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "# 중복제거후\n",
    "exclamation_list_3t = ' '.join(df_3t['exclamation'].dropna().sort_values().drop_duplicates()).split()\n",
    "exclamation_list_3t = list(set(exclamation_list_3t))\n",
    "print(len(exclamation_list_3t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344031a9",
   "metadata": {},
   "source": [
    "#### 감탄사 파일저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0c1d78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(exclamation_list_1t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_1t_exclamation.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "836937a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(exclamation_list_2t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_2t_exclamation.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f6e20723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(exclamation_list_3t,columns=['단어'])\n",
    "tmp['점수'] = ''\n",
    "tmp.to_csv('./data/sentimental_3t_exclamation.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3f334d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>휴</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>에헴</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>앙</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>애고</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>어머나</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    단어  점수\n",
       "0    휴 NaN\n",
       "1   에헴 NaN\n",
       "2    앙 NaN\n",
       "3   애고 NaN\n",
       "4  어머나 NaN"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv('./data/sentimental_1t_exclamation.csv', encoding='cp949')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8de6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
